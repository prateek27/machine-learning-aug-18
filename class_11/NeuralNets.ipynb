{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"./fashion-mnist_test.csv\")\n",
    "X_ = np.array(x)\n",
    "X = X_[:,1:]\n",
    "X = X/255.0\n",
    "y = X_[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:8000,:]\n",
    "X_val = X[8000:,:]\n",
    "y_train = y[:8000]\n",
    "y_val = y[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 28*28\n",
    "H1_SIZE = 256\n",
    "H2_SIZE = 64\n",
    "OUT_SIZE = 10\n",
    "BATCH_SIZE = 256\n",
    "EPOCH = 50\n",
    "ALPHA = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred,y):\n",
    "    return ( 100.0* np.sum(pred==y) / y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_weights():\n",
    "    np.random.seed(0)\n",
    "    model = {}\n",
    "    model['W1'] = np.random.randn(IMG_SIZE,H1_SIZE)/ np.sqrt(IMG_SIZE)\n",
    "    model['B1'] = np.zeros((1,H1_SIZE))\n",
    "    model['W2'] = np.random.randn(H1_SIZE,H2_SIZE)/ np.sqrt(H1_SIZE)\n",
    "    model['B2'] = np.zeros((1,H2_SIZE))\n",
    "    model['W3'] = np.random.randn(H2_SIZE,OUT_SIZE)/ np.sqrt(H2_SIZE)\n",
    "    model['B3'] = np.zeros((1,OUT_SIZE))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(model,x):\n",
    "    z1 = x.dot(model['W1']) + model['B1']\n",
    "    a1 = np.tanh(z1)\n",
    "    z2 = a1.dot(model['W2']) + model['B2']\n",
    "    a2 = np.tanh(z2)\n",
    "    z3 = a2.dot(model['W3']) + model['B3']\n",
    "    h_x = np.exp(z3)\n",
    "    y_out = h_x/ np.sum(h_x, axis=1, keepdims=True)\n",
    "    return a1, a2, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(model, x ,a1 , a2, y, y_out):\n",
    "    delta4 = y_out\n",
    "    delta4[range(y.shape[0]), y] -= 1\n",
    "    dw3 = (a2.T).dot(delta4)\n",
    "    db3 = np.sum(delta4, axis = 0)\n",
    "    delta3 = (1 - np.square(a2))*delta4.dot(model['W3'].T)\n",
    "    dw2 = (a1.T).dot(delta3)\n",
    "    db2 = np.sum(delta3, axis = 0)\n",
    "    delta2 = (1 - np.square(a1))*delta3.dot(model['W2'].T)\n",
    "    dw1 = (x.T).dot(delta2)\n",
    "    db1 = np.sum(delta2, axis = 0)\n",
    "    \n",
    "    model['W1'] += -ALPHA*dw1\n",
    "    model['B1'] += -ALPHA*db1\n",
    "    model['W2'] += -ALPHA*dw2\n",
    "    model['B2'] += -ALPHA*db2\n",
    "    model['W3'] += -ALPHA*dw3\n",
    "    model['B3'] += -ALPHA*db3\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, p, y):\n",
    "    correct_logprobs = -np.log(p[range(y.shape[0]),y])\n",
    "    l = np.sum(correct_logprobs)\n",
    "    \n",
    "    return 1.0/y.shape[0] * l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(y_out):\n",
    "    return np.argmax(y_out, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = initial_weights()\n",
    "    for ix in range(EPOCH):\n",
    "        print (\"\\nEpoch : %d\" %(ix+1))\n",
    "        count = 0\n",
    "        while (count+BATCH_SIZE) < y_train.shape[0]:\n",
    "            batch_data = X_train[count:(count+BATCH_SIZE),:]\n",
    "            batch_labels = y_train[count:(count+BATCH_SIZE),]\n",
    "            count += BATCH_SIZE\n",
    "            \n",
    "            a1, a2 , p = forward_prop(model, batch_data)\n",
    "            model = back_prop(model,batch_data,a1,a2,batch_labels,p)\n",
    "        \n",
    "        _,_, p = forward_prop(model, X_train)\n",
    "        print ('training_loss : % .3f' % (loss(model,p,y_train)))\n",
    "        _,_,p = forward_prop(model, X_val)\n",
    "        pred = predict(p)\n",
    "        print ('val_accuracy : % .3f' % (accuracy(pred,y_val)))\n",
    "        print ('val_loss : % .3f' % loss(model,p,y_val))\n",
    "    print(\"*************Completed***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 1\n",
      "training_loss :  0.766\n",
      "val_accuracy :  71.350\n",
      "val_loss :  0.758\n",
      "\n",
      "Epoch : 2\n",
      "training_loss :  0.662\n",
      "val_accuracy :  75.850\n",
      "val_loss :  0.658\n",
      "\n",
      "Epoch : 3\n",
      "training_loss :  0.580\n",
      "val_accuracy :  78.750\n",
      "val_loss :  0.577\n",
      "\n",
      "Epoch : 4\n",
      "training_loss :  0.562\n",
      "val_accuracy :  78.700\n",
      "val_loss :  0.549\n",
      "\n",
      "Epoch : 5\n",
      "training_loss :  0.536\n",
      "val_accuracy :  79.300\n",
      "val_loss :  0.541\n",
      "\n",
      "Epoch : 6\n",
      "training_loss :  0.521\n",
      "val_accuracy :  80.450\n",
      "val_loss :  0.519\n",
      "\n",
      "Epoch : 7\n",
      "training_loss :  0.497\n",
      "val_accuracy :  81.150\n",
      "val_loss :  0.501\n",
      "\n",
      "Epoch : 8\n",
      "training_loss :  0.501\n",
      "val_accuracy :  80.850\n",
      "val_loss :  0.505\n",
      "\n",
      "Epoch : 9\n",
      "training_loss :  0.506\n",
      "val_accuracy :  80.300\n",
      "val_loss :  0.518\n",
      "\n",
      "Epoch : 10\n",
      "training_loss :  0.458\n",
      "val_accuracy :  81.750\n",
      "val_loss :  0.475\n",
      "\n",
      "Epoch : 11\n",
      "training_loss :  0.447\n",
      "val_accuracy :  82.500\n",
      "val_loss :  0.464\n",
      "\n",
      "Epoch : 12\n",
      "training_loss :  0.450\n",
      "val_accuracy :  82.450\n",
      "val_loss :  0.467\n",
      "\n",
      "Epoch : 13\n",
      "training_loss :  0.442\n",
      "val_accuracy :  82.150\n",
      "val_loss :  0.470\n",
      "\n",
      "Epoch : 14\n",
      "training_loss :  0.441\n",
      "val_accuracy :  82.350\n",
      "val_loss :  0.470\n",
      "\n",
      "Epoch : 15\n",
      "training_loss :  0.413\n",
      "val_accuracy :  83.400\n",
      "val_loss :  0.446\n",
      "\n",
      "Epoch : 16\n",
      "training_loss :  0.403\n",
      "val_accuracy :  84.500\n",
      "val_loss :  0.439\n",
      "\n",
      "Epoch : 17\n",
      "training_loss :  0.394\n",
      "val_accuracy :  84.800\n",
      "val_loss :  0.432\n",
      "\n",
      "Epoch : 18\n",
      "training_loss :  0.391\n",
      "val_accuracy :  84.550\n",
      "val_loss :  0.434\n",
      "\n",
      "Epoch : 19\n",
      "training_loss :  0.385\n",
      "val_accuracy :  84.300\n",
      "val_loss :  0.433\n",
      "\n",
      "Epoch : 20\n",
      "training_loss :  0.380\n",
      "val_accuracy :  84.600\n",
      "val_loss :  0.431\n",
      "\n",
      "Epoch : 21\n",
      "training_loss :  0.373\n",
      "val_accuracy :  84.900\n",
      "val_loss :  0.428\n",
      "\n",
      "Epoch : 22\n",
      "training_loss :  0.366\n",
      "val_accuracy :  85.100\n",
      "val_loss :  0.425\n",
      "\n",
      "Epoch : 23\n",
      "training_loss :  0.362\n",
      "val_accuracy :  85.050\n",
      "val_loss :  0.426\n",
      "\n",
      "Epoch : 24\n",
      "training_loss :  0.384\n",
      "val_accuracy :  84.150\n",
      "val_loss :  0.448\n",
      "\n",
      "Epoch : 25\n",
      "training_loss :  0.339\n",
      "val_accuracy :  84.600\n",
      "val_loss :  0.419\n",
      "\n",
      "Epoch : 26\n",
      "training_loss :  0.316\n",
      "val_accuracy :  85.800\n",
      "val_loss :  0.398\n",
      "\n",
      "Epoch : 27\n",
      "training_loss :  0.343\n",
      "val_accuracy :  84.950\n",
      "val_loss :  0.422\n",
      "\n",
      "Epoch : 28\n",
      "training_loss :  0.435\n",
      "val_accuracy :  83.200\n",
      "val_loss :  0.498\n",
      "\n",
      "Epoch : 29\n",
      "training_loss :  0.331\n",
      "val_accuracy :  85.200\n",
      "val_loss :  0.421\n",
      "\n",
      "Epoch : 30\n",
      "training_loss :  0.287\n",
      "val_accuracy :  86.300\n",
      "val_loss :  0.389\n",
      "\n",
      "Epoch : 31\n",
      "training_loss :  0.336\n",
      "val_accuracy :  85.200\n",
      "val_loss :  0.429\n",
      "\n",
      "Epoch : 32\n",
      "training_loss :  0.298\n",
      "val_accuracy :  85.850\n",
      "val_loss :  0.402\n",
      "\n",
      "Epoch : 33\n",
      "training_loss :  0.327\n",
      "val_accuracy :  85.300\n",
      "val_loss :  0.427\n",
      "\n",
      "Epoch : 34\n",
      "training_loss :  0.292\n",
      "val_accuracy :  85.800\n",
      "val_loss :  0.405\n",
      "\n",
      "Epoch : 35\n",
      "training_loss :  0.280\n",
      "val_accuracy :  85.700\n",
      "val_loss :  0.399\n",
      "\n",
      "Epoch : 36\n",
      "training_loss :  0.271\n",
      "val_accuracy :  85.750\n",
      "val_loss :  0.395\n",
      "\n",
      "Epoch : 37\n",
      "training_loss :  0.264\n",
      "val_accuracy :  86.150\n",
      "val_loss :  0.394\n",
      "\n",
      "Epoch : 38\n",
      "training_loss :  0.261\n",
      "val_accuracy :  85.800\n",
      "val_loss :  0.393\n",
      "\n",
      "Epoch : 39\n",
      "training_loss :  0.254\n",
      "val_accuracy :  86.150\n",
      "val_loss :  0.391\n",
      "\n",
      "Epoch : 40\n",
      "training_loss :  0.551\n",
      "val_accuracy :  81.350\n",
      "val_loss :  0.624\n",
      "\n",
      "Epoch : 41\n",
      "training_loss :  0.254\n",
      "val_accuracy :  86.250\n",
      "val_loss :  0.394\n",
      "\n",
      "Epoch : 42\n",
      "training_loss :  0.262\n",
      "val_accuracy :  85.850\n",
      "val_loss :  0.404\n",
      "\n",
      "Epoch : 43\n",
      "training_loss :  0.249\n",
      "val_accuracy :  86.000\n",
      "val_loss :  0.399\n",
      "\n",
      "Epoch : 44\n",
      "training_loss :  0.313\n",
      "val_accuracy :  84.700\n",
      "val_loss :  0.450\n",
      "\n",
      "Epoch : 45\n",
      "training_loss :  0.234\n",
      "val_accuracy :  86.400\n",
      "val_loss :  0.395\n",
      "\n",
      "Epoch : 46\n",
      "training_loss :  0.242\n",
      "val_accuracy :  86.000\n",
      "val_loss :  0.402\n",
      "\n",
      "Epoch : 47\n",
      "training_loss :  0.319\n",
      "val_accuracy :  84.450\n",
      "val_loss :  0.465\n",
      "\n",
      "Epoch : 48\n",
      "training_loss :  0.272\n",
      "val_accuracy :  85.500\n",
      "val_loss :  0.430\n",
      "\n",
      "Epoch : 49\n",
      "training_loss :  0.423\n",
      "val_accuracy :  82.600\n",
      "val_loss :  0.553\n",
      "\n",
      "Epoch : 50\n",
      "training_loss :  0.223\n",
      "val_accuracy :  86.750\n",
      "val_loss :  0.400\n",
      "*************Completed***********\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
